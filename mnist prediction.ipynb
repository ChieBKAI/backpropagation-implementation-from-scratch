{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mnist data from local file\n",
    "def get_mnist_data():\n",
    "    mnist_file_path = pathlib.Path(\"data\\mnist.npz\")\n",
    "    with np.load(mnist_file_path) as f:\n",
    "        images, labels = f[\"x_train\"], f[\"y_train\"]\n",
    "    images = images.astype(\"float32\") / 255.0\n",
    "    images = np.reshape(images, (images.shape[0], images.shape[1] * images.shape[2]))\n",
    "    labels = np.eye(10)[labels]\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(Z):\n",
    "    e_Z = np.exp(Z - np.max(Z, axis = 0, keepdims = True))\n",
    "    A = e_Z / e_Z.sum(axis = 0)\n",
    "    return A\n",
    "\n",
    "def forward_propagation(w1, b1, w2, b2, X):\n",
    "    z1 = np.dot(w1, X) + b1\n",
    "    a1 = ReLU(z1)\n",
    "    z2 = np.dot(w2, a1) + b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "def back_propagation(z1, a1, w2, a2, X, y):\n",
    "    dz2 = 2 * (a2 - y)\n",
    "    dw2 = np.dot(dz2, a1.T)# / X.shape[1]    it's all about the gradient, if we set the learning rate small enough, we don't need to divide by the number of samples\n",
    "    db2 = np.sum(dz2, axis=1, keepdims=True)# / X.shape[1] \n",
    "    dz1 = np.dot(w2.T, dz2) * (z1 > 0) \n",
    "    dw1 = np.dot(dz1, X.T)# / X.shape[1] \n",
    "    db1 = np.sum(dz1, axis=1, keepdims=True)# / X.shape[1] \n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "def update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, learning_rate):\n",
    "    w1 -= learning_rate * dw1\n",
    "    b1 -= learning_rate * np.reshape(db1, (db1.shape[0], 1))\n",
    "    w2 -= learning_rate * dw2\n",
    "    b2 -= learning_rate * np.reshape(db2, (db2.shape[0], 1))\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def get_predictions(a2):\n",
    "    return np.argmax(a2, axis=0)\n",
    "\n",
    "def get_accuracy(predictions, y):\n",
    "    return  np.sum(predictions == y) / y.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get data from mnist dataset\n",
    "images, labels = get_mnist_data()\n",
    "m, n = images.shape\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Accuracy:  0.10905555555555556\n",
      "Epoch:  10\n",
      "Accuracy:  0.5479444444444445\n",
      "Epoch:  20\n",
      "Accuracy:  0.7316111111111111\n",
      "Epoch:  30\n",
      "Accuracy:  0.7347592592592592\n",
      "Epoch:  40\n",
      "Accuracy:  0.8047407407407408\n",
      "Epoch:  50\n",
      "Accuracy:  0.8295370370370371\n",
      "Epoch:  60\n",
      "Accuracy:  0.8402407407407407\n",
      "Epoch:  70\n",
      "Accuracy:  0.8584259259259259\n",
      "Epoch:  80\n",
      "Accuracy:  0.8719629629629629\n",
      "Epoch:  90\n",
      "Accuracy:  0.8797407407407407\n",
      "Epoch:  100\n",
      "Accuracy:  0.8847407407407407\n",
      "Epoch:  110\n",
      "Accuracy:  0.8885740740740741\n",
      "Epoch:  120\n",
      "Accuracy:  0.8917777777777778\n",
      "Epoch:  130\n",
      "Accuracy:  0.8937962962962963\n",
      "Epoch:  140\n",
      "Accuracy:  0.8951296296296296\n",
      "Epoch:  150\n",
      "Accuracy:  0.896\n",
      "Epoch:  160\n",
      "Accuracy:  0.8970370370370371\n",
      "Epoch:  170\n",
      "Accuracy:  0.8991111111111111\n",
      "Epoch:  180\n",
      "Accuracy:  0.9012592592592592\n",
      "Epoch:  190\n",
      "Accuracy:  0.9033148148148148\n",
      "Epoch:  200\n",
      "Accuracy:  0.9045740740740741\n",
      "Epoch:  210\n",
      "Accuracy:  0.9057962962962963\n",
      "Epoch:  220\n",
      "Accuracy:  0.9068333333333334\n",
      "Epoch:  230\n",
      "Accuracy:  0.9079444444444444\n",
      "Epoch:  240\n",
      "Accuracy:  0.908537037037037\n",
      "Epoch:  250\n",
      "Accuracy:  0.9092962962962963\n",
      "Epoch:  260\n",
      "Accuracy:  0.9093888888888889\n",
      "Epoch:  270\n",
      "Accuracy:  0.9087777777777778\n",
      "Epoch:  280\n",
      "Accuracy:  0.9083703703703704\n",
      "Epoch:  290\n",
      "Accuracy:  0.9082777777777777\n",
      "Epoch:  300\n",
      "Accuracy:  0.9094629629629629\n",
      "Epoch:  310\n",
      "Accuracy:  0.911425925925926\n",
      "Epoch:  320\n",
      "Accuracy:  0.913\n",
      "Epoch:  330\n",
      "Accuracy:  0.9142592592592592\n",
      "Epoch:  340\n",
      "Accuracy:  0.9150185185185186\n",
      "Epoch:  350\n",
      "Accuracy:  0.9153148148148148\n",
      "Epoch:  360\n",
      "Accuracy:  0.9156666666666666\n",
      "Epoch:  370\n",
      "Accuracy:  0.9157037037037037\n",
      "Epoch:  380\n",
      "Accuracy:  0.9153703703703704\n",
      "Epoch:  390\n",
      "Accuracy:  0.9154629629629629\n",
      "Epoch:  400\n",
      "Accuracy:  0.9163888888888889\n",
      "Epoch:  410\n",
      "Accuracy:  0.9177222222222222\n",
      "Epoch:  420\n",
      "Accuracy:  0.9189259259259259\n",
      "Epoch:  430\n",
      "Accuracy:  0.9196666666666666\n",
      "Epoch:  440\n",
      "Accuracy:  0.9205555555555556\n",
      "Epoch:  450\n",
      "Accuracy:  0.9211296296296296\n",
      "Epoch:  460\n",
      "Accuracy:  0.9216481481481481\n",
      "Epoch:  470\n",
      "Accuracy:  0.9220925925925926\n",
      "Epoch:  480\n",
      "Accuracy:  0.922074074074074\n",
      "Epoch:  490\n",
      "Accuracy:  0.9218333333333333\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1)\n",
    "\n",
    "#change dimension of the data\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "#Train the model\n",
    "node_num = 10\n",
    "learning_rate = 0.000003\n",
    "epochs = 500\n",
    "#He initialization\n",
    "w1 = np.random.randn(node_num, 784) * np.sqrt(2/784)\n",
    "b1 = np.zeros((node_num, 1))\n",
    "w2 = np.random.randn(10, node_num) * np.sqrt(2/node_num)\n",
    "b2 = np.zeros((10, 1))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    z1, a1, z2, a2 = forward_propagation(w1, b1, w2, b2, X_train)\n",
    "    dw1, db1, dw2, db2 = back_propagation(z1, a1, w2, a2, X_train, y_train)\n",
    "    w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, learning_rate)\n",
    "    if (epoch % 10 == 0):\n",
    "        print (\"Epoch: \", epoch)\n",
    "        print (\"Accuracy: \", get_accuracy(get_predictions(a2), get_predictions(y_train)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  91.83333333333333 %\n"
     ]
    }
   ],
   "source": [
    "z1, a1, z2, a2 = forward_propagation(w1, b1, w2, b2, X_test)\n",
    "print (\"Accuracy: \", get_accuracy(get_predictions(a2), get_predictions(y_test)) * 100, \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  7\n",
      "Label:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 207\n",
    "vect_X = X_test[:, index,None]\n",
    "prediction = get_predictions(a2)\n",
    "label = get_predictions(y_test[:, index])\n",
    "print(\"Prediction: \", prediction[index])\n",
    "print(\"Label: \", label)\n",
    "\n",
    "current_image = vect_X.reshape((28, 28)) * 255.0\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(current_image, interpolation='nearest')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

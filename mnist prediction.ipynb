{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mnist data from local file\n",
    "def get_mnist_data():\n",
    "    mnist_file_path = pathlib.Path(\"data\\mnist.npz\")\n",
    "    with np.load(mnist_file_path) as f:\n",
    "        images, labels = f[\"x_train\"], f[\"y_train\"]\n",
    "    images = images.astype(\"float32\") / 255.0\n",
    "    images = np.reshape(images, (images.shape[0], images.shape[1] * images.shape[2]))\n",
    "    labels = np.eye(10)[labels]\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(Z):\n",
    "    e_Z = np.exp(Z - np.max(Z, axis = 0, keepdims = True))\n",
    "    A = e_Z / e_Z.sum(axis = 0)\n",
    "    return A\n",
    "\n",
    "def forward_propagation(w1, b1, w2, b2, X):\n",
    "    z1 = np.dot(w1, X) + b1\n",
    "    a1 = ReLU(z1)\n",
    "    z2 = np.dot(w2, a1) + b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "def back_propagation(z1, a1, w2, a2, X, y):\n",
    "    dz2 = 2 * (a2 - y)\n",
    "    dw2 = np.dot(dz2, a1.T)# / X.shape[1]    it's all about the gradient, if we set the learning rate small enough, we don't need to divide by the number of samples\n",
    "    db2 = np.sum(dz2, axis=1, keepdims=True)# / X.shape[1] \n",
    "    dz1 = np.dot(w2.T, dz2) * (z1 > 0) \n",
    "    dw1 = np.dot(dz1, X.T)# / X.shape[1] \n",
    "    db1 = np.sum(dz1, axis=1, keepdims=True)# / X.shape[1] \n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "def update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, learning_rate):\n",
    "    w1 -= learning_rate * dw1\n",
    "    b1 -= learning_rate * np.reshape(db1, (db1.shape[0], 1))\n",
    "    w2 -= learning_rate * dw2\n",
    "    b2 -= learning_rate * np.reshape(db2, (db2.shape[0], 1))\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def get_predictions(a2):\n",
    "    return np.argmax(a2, axis=0)\n",
    "\n",
    "def get_accuracy(predictions, y):\n",
    "    return  np.sum(predictions == y) / y.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get data from mnist dataset\n",
    "images, labels = get_mnist_data()\n",
    "m, n = images.shape\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Accuracy:  0.12496296296296296\n",
      "Epoch:  10\n",
      "Accuracy:  0.6539074074074074\n",
      "Epoch:  20\n",
      "Accuracy:  0.7811666666666667\n",
      "Epoch:  30\n",
      "Accuracy:  0.8612962962962963\n",
      "Epoch:  40\n",
      "Accuracy:  0.871\n",
      "Epoch:  50\n",
      "Accuracy:  0.889\n",
      "Epoch:  60\n",
      "Accuracy:  0.8947037037037037\n",
      "Epoch:  70\n",
      "Accuracy:  0.8990555555555556\n",
      "Epoch:  80\n",
      "Accuracy:  0.9022407407407408\n",
      "Epoch:  90\n",
      "Accuracy:  0.9056481481481482\n",
      "Epoch:  100\n",
      "Accuracy:  0.9082962962962963\n",
      "Epoch:  110\n",
      "Accuracy:  0.9104444444444444\n",
      "Epoch:  120\n",
      "Accuracy:  0.9122222222222223\n",
      "Epoch:  130\n",
      "Accuracy:  0.914074074074074\n",
      "Epoch:  140\n",
      "Accuracy:  0.9158333333333334\n",
      "Epoch:  150\n",
      "Accuracy:  0.917537037037037\n",
      "Epoch:  160\n",
      "Accuracy:  0.9188518518518518\n",
      "Epoch:  170\n",
      "Accuracy:  0.9199074074074074\n",
      "Epoch:  180\n",
      "Accuracy:  0.9212037037037037\n",
      "Epoch:  190\n",
      "Accuracy:  0.9223703703703704\n",
      "Epoch:  200\n",
      "Accuracy:  0.9236296296296296\n",
      "Epoch:  210\n",
      "Accuracy:  0.9247777777777778\n",
      "Epoch:  220\n",
      "Accuracy:  0.9255555555555556\n",
      "Epoch:  230\n",
      "Accuracy:  0.9265925925925926\n",
      "Epoch:  240\n",
      "Accuracy:  0.9274074074074075\n",
      "Epoch:  250\n",
      "Accuracy:  0.9283148148148148\n",
      "Epoch:  260\n",
      "Accuracy:  0.929074074074074\n",
      "Epoch:  270\n",
      "Accuracy:  0.9300925925925926\n",
      "Epoch:  280\n",
      "Accuracy:  0.9308518518518518\n",
      "Epoch:  290\n",
      "Accuracy:  0.9318888888888889\n",
      "Epoch:  300\n",
      "Accuracy:  0.9326481481481481\n",
      "Epoch:  310\n",
      "Accuracy:  0.9338703703703704\n",
      "Epoch:  320\n",
      "Accuracy:  0.9346111111111111\n",
      "Epoch:  330\n",
      "Accuracy:  0.9353148148148148\n",
      "Epoch:  340\n",
      "Accuracy:  0.9359444444444445\n",
      "Epoch:  350\n",
      "Accuracy:  0.9367592592592593\n",
      "Epoch:  360\n",
      "Accuracy:  0.9375740740740741\n",
      "Epoch:  370\n",
      "Accuracy:  0.9382037037037037\n",
      "Epoch:  380\n",
      "Accuracy:  0.9388888888888889\n",
      "Epoch:  390\n",
      "Accuracy:  0.9397407407407408\n",
      "Epoch:  400\n",
      "Accuracy:  0.9403333333333334\n",
      "Epoch:  410\n",
      "Accuracy:  0.9407592592592593\n",
      "Epoch:  420\n",
      "Accuracy:  0.9412777777777778\n",
      "Epoch:  430\n",
      "Accuracy:  0.9416666666666667\n",
      "Epoch:  440\n",
      "Accuracy:  0.9422037037037037\n",
      "Epoch:  450\n",
      "Accuracy:  0.9427222222222222\n",
      "Epoch:  460\n",
      "Accuracy:  0.9431296296296297\n",
      "Epoch:  470\n",
      "Accuracy:  0.9436851851851852\n",
      "Epoch:  480\n",
      "Accuracy:  0.9441111111111111\n",
      "Epoch:  490\n",
      "Accuracy:  0.9445925925925925\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "#change dimension of the data\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "#Train the model\n",
    "node_num = 30\n",
    "learning_rate = 0.000003\n",
    "epochs = 500\n",
    "#He initialization\n",
    "w1 = np.random.randn(node_num, 784) * np.sqrt(2/784)\n",
    "b1 = np.zeros((node_num, 1))\n",
    "w2 = np.random.randn(10, node_num) * np.sqrt(2/node_num)\n",
    "b2 = np.zeros((10, 1))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    z1, a1, z2, a2 = forward_propagation(w1, b1, w2, b2, X_train)\n",
    "    dw1, db1, dw2, db2 = back_propagation(z1, a1, w2, a2, X_train, y_train)\n",
    "    w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, learning_rate)\n",
    "    if (epoch % 10 == 0):\n",
    "        print (\"Epoch: \", epoch)\n",
    "        print (\"Accuracy: \", get_accuracy(get_predictions(a2), get_predictions(y_train)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  94.25 %\n"
     ]
    }
   ],
   "source": [
    "z1, a1, z2, a2 = forward_propagation(w1, b1, w2, b2, X_test)\n",
    "print (\"Accuracy: \", get_accuracy(get_predictions(a2), get_predictions(y_test)) * 100, \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  5\n",
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 207\n",
    "vect_X = X_test[:, index,None]\n",
    "prediction = get_predictions(a2)\n",
    "label = get_predictions(y_test[:, index])\n",
    "print(\"Prediction: \", prediction[index])\n",
    "print(\"Label: \", label)\n",
    "\n",
    "current_image = vect_X.reshape((28, 28)) * 255.0\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(current_image, interpolation='nearest')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
